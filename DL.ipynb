{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74738876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56.59s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirement.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: optuna>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirement.txt (line 2)) (4.6.0)\n",
      "Requirement already satisfied: shap>=0.44.0 in /usr/local/lib/python3.10/dist-packages (from -r requirement.txt (line 3)) (0.49.1)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirement.txt (line 4)) (1.7.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirement.txt (line 5)) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirement.txt (line 6)) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirement.txt (line 7)) (3.10.7)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirement.txt (line 8)) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost>=2.0.0->-r requirement.txt (line 1)) (1.15.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost>=2.0.0->-r requirement.txt (line 1)) (2.28.9)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->-r requirement.txt (line 2)) (2.0.44)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->-r requirement.txt (line 2)) (6.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->-r requirement.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->-r requirement.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->-r requirement.txt (line 2)) (1.17.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna>=3.0.0->-r requirement.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from shap>=0.44.0->-r requirement.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap>=0.44.0->-r requirement.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap>=0.44.0->-r requirement.txt (line 3)) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.10/dist-packages (from shap>=0.44.0->-r requirement.txt (line 3)) (0.62.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->-r requirement.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirement.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirement.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirement.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirement.txt (line 7)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirement.txt (line 7)) (3.2.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirement.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirement.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirement.txt (line 7)) (1.4.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirement.txt (line 7)) (4.60.1)\n",
      "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.0.0->-r requirement.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.0.0->-r requirement.txt (line 2)) (1.3.10)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.54->shap>=0.44.0->-r requirement.txt (line 3)) (0.45.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirement.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.0.0->-r requirement.txt (line 2)) (3.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna>=3.0.0->-r requirement.txt (line 2)) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac4446c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.13.5)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: PySocks, filelock, gdown\n",
      "Successfully installed PySocks-1.7.1 filelock-3.20.0 gdown-5.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb935b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97.17s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1kQWXnghhRhZ1U06x_l3UXOUiCYy1doTX\n",
      "From (redirected): https://drive.google.com/uc?id=1kQWXnghhRhZ1U06x_l3UXOUiCYy1doTX&confirm=t&uuid=51e6c1d1-1ff4-4065-b01e-255325eff2ef\n",
      "To: /root/AIUET/DakLak_Full_Merged.tif\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1G/14.1G [05:16<00:00, 44.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1kQWXnghhRhZ1U06x_l3UXOUiCYy1doTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381dd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import os\n",
    "import math # ThÃªm math cho má»™t sá»‘ tÃ­nh toÃ¡n náº¿u cáº§n\n",
    "\n",
    "# ================================================================================\n",
    "# CANOPY HEIGHT MAPPING - UNET++ TRAINING (FINAL OPTIMIZED)\n",
    "# ================================================================================\n",
    "\n",
    "# ================= 1. CONFIGURATION =================\n",
    "class Config:\n",
    "    # --- File Paths ---\n",
    "    TIFF_PATH = \"./LamDong_Composite.tif\"\n",
    "    MODEL_SAVE_PATH = \"best_unetpp_canopy_height.pth\"\n",
    "    \n",
    "    # --- Training Hyperparameters ---\n",
    "    PATCH_SIZE = 256\n",
    "    BATCH_SIZE = 24  \n",
    "    LR = 1e-4  # LR ban Ä‘áº§u cho AdamW/Plateau\n",
    "    EPOCHS = 200\n",
    "    EARLY_STOP_PATIENCE = 15\n",
    "    \n",
    "    # --- Data Params ---\n",
    "    MAX_CANOPY_HEIGHT = 100.0  \n",
    "    \n",
    "    # --- Band Configuration ---\n",
    "    # Band 1: GEDI Label (RH98) - Target\n",
    "    # Band 2-15: Sentinel-1 & Sentinel-2 Inputs (14 kÃªnh)\n",
    "    LABEL_BAND_IDX = 1\n",
    "    INPUT_BAND_INDICES = list(range(2, 16))\n",
    "    INPUT_CHANNELS = 14\n",
    "    \n",
    "    # --- System ---\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    NUM_WORKERS = 4 \n",
    "    PIN_MEMORY = True\n",
    "    \n",
    "    # --- Split Ratio & Seed ---\n",
    "    TRAIN_RATIO = 0.8\n",
    "    VAL_RATIO = 0.2\n",
    "    SEED = 42\n",
    "\n",
    "# ================= 2. DATASET =================\n",
    "class CanopyHeightDataset(Dataset):\n",
    "    def __init__(self, tif_path, config, augment=True):\n",
    "        self.tif_path = tif_path\n",
    "        self.cfg = config\n",
    "        self.augment = augment\n",
    "        self.windows = []\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DATASET INITIALIZATION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        if not os.path.exists(tif_path):\n",
    "            raise FileNotFoundError(f\"âŒ KhÃ´ng tÃ¬m tháº¥y file: {tif_path}\")\n",
    "\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            self.H, self.W = src.height, src.width\n",
    "            print(f\"Image Size: {self.H} x {self.W}\")\n",
    "            print(\"Loading label band to generate patches...\")\n",
    "            \n",
    "            try:\n",
    "                label_data = src.read(config.LABEL_BAND_IDX)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error reading label: {e}\")\n",
    "                return\n",
    "        \n",
    "        patch_size = config.PATCH_SIZE\n",
    "        stride = patch_size\n",
    "        \n",
    "        n_rows = (self.H - patch_size) // stride + 1\n",
    "        n_cols = (self.W - patch_size) // stride + 1\n",
    "        \n",
    "        gedi_pixels_total = 0\n",
    "        \n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_cols):\n",
    "                row_off = i * stride\n",
    "                col_off = j * stride\n",
    "                \n",
    "                window = rasterio.windows.Window(col_off, row_off, patch_size, patch_size)\n",
    "                patch_label = label_data[row_off:row_off+patch_size, col_off:col_off+patch_size]\n",
    "                \n",
    "                # Lá»ŒC: Chá»‰ láº¥y patch cÃ³ Ã­t nháº¥t 1 Ä‘iá»ƒm GEDI há»£p lá»‡ (>0.5m)\n",
    "                valid_gedi = ((patch_label > 0.5) & (patch_label < 100)).sum()\n",
    "                \n",
    "                if valid_gedi > 0:\n",
    "                    self.windows.append(window)\n",
    "                    gedi_pixels_total += valid_gedi\n",
    "                    \n",
    "        print(f\"âœ… Valid Patches found: {len(self.windows)}\")\n",
    "        print(f\"âœ… Total GEDI Pixels: {gedi_pixels_total}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window = self.windows[idx]\n",
    "        \n",
    "        with rasterio.open(self.tif_path) as src:\n",
    "            img = src.read(self.cfg.INPUT_BAND_INDICES, window=window).astype('float32')\n",
    "            label = src.read(self.cfg.LABEL_BAND_IDX, window=window).astype('float32')\n",
    "        \n",
    "        img = np.nan_to_num(img, nan=0.0)\n",
    "        img = np.clip(img, 0, 1.0)\n",
    "        \n",
    "        label = np.nan_to_num(label, nan=0.0)\n",
    "        mask = ((label > 0.5) & (label < 100.0)).astype('float32')\n",
    "        \n",
    "        label = np.clip(label, 0, self.cfg.MAX_CANOPY_HEIGHT) / self.cfg.MAX_CANOPY_HEIGHT\n",
    "        label = label * mask \n",
    "        \n",
    "        img_t = torch.from_numpy(img)\n",
    "        label_t = torch.from_numpy(label).unsqueeze(0)\n",
    "        mask_t = torch.from_numpy(mask).unsqueeze(0)\n",
    "        \n",
    "        # Augmentation\n",
    "        if self.augment:\n",
    "            if random.random() > 0.5:\n",
    "                img_t = TF.hflip(img_t)\n",
    "                label_t = TF.hflip(label_t)\n",
    "                mask_t = TF.hflip(mask_t)\n",
    "            if random.random() > 0.5:\n",
    "                img_t = TF.vflip(img_t)\n",
    "                label_t = TF.vflip(label_t)\n",
    "                mask_t = TF.vflip(mask_t)\n",
    "            if random.random() > 0.5:\n",
    "                angle = random.choice([90, 180, 270])\n",
    "                img_t = TF.rotate(img_t, angle)\n",
    "                label_t = TF.rotate(label_t, angle)\n",
    "                mask_t = TF.rotate(mask_t, angle)\n",
    "                \n",
    "        return img_t, label_t, mask_t\n",
    "\n",
    "# ================= 3. MODEL (UNet++) =================\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.conv(x)\n",
    "\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    def __init__(self, in_channels=12, out_channels=1):\n",
    "        super(UNetPlusPlus, self).__init__()\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv0_0 = ConvBlock(in_channels, nb_filter[0])\n",
    "        self.conv1_0 = ConvBlock(nb_filter[0], nb_filter[1])\n",
    "        self.conv2_0 = ConvBlock(nb_filter[1], nb_filter[2])\n",
    "        self.conv3_0 = ConvBlock(nb_filter[2], nb_filter[3])\n",
    "        self.conv4_0 = ConvBlock(nb_filter[3], nb_filter[4])\n",
    "        \n",
    "        self.conv0_1 = ConvBlock(nb_filter[0]+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_1 = ConvBlock(nb_filter[1]+nb_filter[2], nb_filter[1])\n",
    "        self.conv2_1 = ConvBlock(nb_filter[2]+nb_filter[3], nb_filter[2])\n",
    "        self.conv3_1 = ConvBlock(nb_filter[3]+nb_filter[4], nb_filter[3])\n",
    "        \n",
    "        self.conv0_2 = ConvBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_2 = ConvBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1])\n",
    "        self.conv2_2 = ConvBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2])\n",
    "        \n",
    "        self.conv0_3 = ConvBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_3 = ConvBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1])\n",
    "        \n",
    "        self.conv0_4 = ConvBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0])\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(nb_filter[0], out_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "        \n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "        \n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "        \n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "        \n",
    "        output = self.final(x0_4)\n",
    "        return output\n",
    "\n",
    "# ================= 4. LOSS & METRICS =================\n",
    "def masked_mae_loss(preds, targets, mask):\n",
    "    \"\"\"TÃ­nh Loss trÃªn thang Ä‘o [0, 1] cho Regression (MAE).\"\"\"\n",
    "    diff = torch.abs(preds - targets) * mask\n",
    "    loss = diff.sum() / (mask.sum() + 1e-6)\n",
    "    return loss\n",
    "\n",
    "def calculate_metrics(preds, targets, mask, max_height=100.0):\n",
    "    \"\"\"TÃ­nh Metrics bÃ¡o cÃ¡o (R2, RMSE, MAE) trÃªn thang Ä‘o THá»°C Táº¾ (mÃ©t).\"\"\"\n",
    "    preds_m = preds * max_height\n",
    "    targets_m = targets * max_height\n",
    "    \n",
    "    p = preds_m.detach().cpu().numpy().flatten()\n",
    "    t = targets_m.detach().cpu().numpy().flatten()\n",
    "    m = mask.detach().cpu().numpy().flatten()\n",
    "    \n",
    "    valid_indices = m > 0\n",
    "    if valid_indices.sum() < 2:\n",
    "        return {'r2': 0.0, 'rmse': 0.0, 'mae': 0.0}\n",
    "        \n",
    "    p_valid = p[valid_indices]\n",
    "    t_valid = t[valid_indices]\n",
    "    \n",
    "    valid_mask = np.isfinite(p_valid) & np.isfinite(t_valid)\n",
    "    p_valid = p_valid[valid_mask]\n",
    "    t_valid = t_valid[valid_mask]\n",
    "    \n",
    "    if len(p_valid) < 2:\n",
    "        return {'r2': 0.0, 'rmse': 0.0, 'mae': 0.0}\n",
    "        \n",
    "    r2 = r2_score(t_valid, p_valid)\n",
    "    rmse = np.sqrt(mean_squared_error(t_valid, p_valid))\n",
    "    mae = mean_absolute_error(t_valid, p_valid)\n",
    "    \n",
    "    return {'r2': r2, 'rmse': rmse, 'mae': mae}\n",
    "\n",
    "# ================= 5. TRAINING ROUTINE =================\n",
    "def train_one_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    metrics_accum = {'r2': 0, 'rmse': 0, 'mae': 0}\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Train\")\n",
    "    for img, label, mask in pbar:\n",
    "        img, label, mask = img.to(device), label.to(device), mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(img)\n",
    "        \n",
    "        loss = masked_mae_loss(preds, label, mask)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # NOTE: Scheduler.step() Ä‘Æ°á»£c gá»i trong main() náº¿u dÃ¹ng Plateau\n",
    "        if scheduler: # Chá»‰ cháº¡y náº¿u lÃ  OneCycleLR\n",
    "             scheduler.step()\n",
    "            \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_metrics = calculate_metrics(preds, label, mask, Config.MAX_CANOPY_HEIGHT)\n",
    "            for k in metrics_accum:\n",
    "                metrics_accum[k] += batch_metrics[k]\n",
    "                \n",
    "        pbar.set_postfix({'Loss': f\"{loss.item():.4f}\", 'MAE': f\"{batch_metrics['mae']:.2f}m\"})\n",
    "        \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    avg_metrics = {k: v / len(dataloader) for k, v in metrics_accum.items()}\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    metrics_accum = {'r2': 0, 'rmse': 0, 'mae': 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, label, mask in tqdm(dataloader, desc=\"Val\"):\n",
    "            img, label, mask = img.to(device), label.to(device), mask.to(device)\n",
    "            \n",
    "            preds = model(img)\n",
    "            loss = masked_mae_loss(preds, label, mask)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            batch_metrics = calculate_metrics(preds, label, mask, Config.MAX_CANOPY_HEIGHT)\n",
    "            for k in metrics_accum:\n",
    "                metrics_accum[k] += batch_metrics[k]\n",
    "                \n",
    "    avg_loss = val_loss / len(dataloader)\n",
    "    avg_metrics = {k: v / len(dataloader) for k, v in metrics_accum.items()}\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "\n",
    "# ================= 6. MAIN (Sá»¬ Dá»¤NG REDUCELRONPLATEAU) =================\n",
    "def main():\n",
    "    cfg = Config()\n",
    "    \n",
    "    # 1. Reproducibility\n",
    "    random.seed(cfg.SEED)\n",
    "    np.random.seed(cfg.SEED)\n",
    "    torch.manual_seed(cfg.SEED)\n",
    "    \n",
    "    # 2. Dataset Setup\n",
    "    if not os.path.exists(cfg.TIFF_PATH):\n",
    "        print(f\"âŒ Error: Not found {cfg.TIFF_PATH}\")\n",
    "        return\n",
    "\n",
    "    full_dataset = CanopyHeightDataset(cfg.TIFF_PATH, cfg, augment=False) # Táº¯t Augmentation khi debug/máº¯c káº¹t\n",
    "    \n",
    "    train_size = int(cfg.TRAIN_RATIO * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_ds, val_ds = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(cfg.SEED)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    print(f\"Train size: {len(train_ds)} patches\")\n",
    "    print(f\"Val size: Â  {len(val_ds)} patches\")\n",
    "    \n",
    "    # 3. Model & Optimizer Setup\n",
    "    \n",
    "    # Khá»Ÿi táº¡o model vÃ  optimizer CHÃNH THá»¨C\n",
    "    model = UNetPlusPlus(in_channels=cfg.INPUT_CHANNELS, out_channels=1).to(cfg.DEVICE)\n",
    "    \n",
    "    # Sá»¬ Dá»¤NG WEIGHT_DECAY TÄ‚NG LÃŠN 5E-4 VÃ€ LR BAN Äáº¦U\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=5e-4) \n",
    "    \n",
    "    # KHá»žI Táº O SCHEDULER THEO HIá»†U SUáº¤T (ReduceLROnPlateau)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min',         # Theo dÃµi Loss Validation (Loss giáº£m)\n",
    "        factor=0.5,         # Giáº£m LR Ä‘i 50%\n",
    "        patience=5,         # Chá» 5 Epoch khÃ´ng cáº£i thiá»‡n má»›i giáº£m\n",
    "        min_lr=1e-7,        # LR tá»‘i thiá»ƒu\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # 4. Loop\n",
    "    # NOTE: Náº¿u báº¡n muá»‘n Fine-tune tá»« Epoch 11, hÃ£y uncomment dÃ²ng sau:\n",
    "    # model.load_state_dict(torch.load(cfg.MODEL_SAVE_PATH))\n",
    "    best_mae = float('inf')\n",
    "    patience = 0\n",
    "    \n",
    "    print(\"\\nðŸš€ START TRAINING with ReduceLROnPlateau...\")\n",
    "    for epoch in range(1, cfg.EPOCHS+1):\n",
    "        # Truyá»n None cho train_one_epoch Ä‘á»ƒ khÃ´ng gá»i scheduler.step() sau má»—i batch\n",
    "        train_loss, train_m = train_one_epoch(model, train_loader, optimizer, None, cfg.DEVICE) \n",
    "        val_loss, val_m = validate(model, val_loader, cfg.DEVICE)\n",
    "        \n",
    "        # Gá»ŒI SCHEDULER.STEP() Vá»šI VALIDATION LOSS\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{cfg.EPOCHS}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | MAE: {train_m['mae']:.2f}m | RMSE: {train_m['rmse']:.2f}m | R2: {train_m['r2']:.4f}\")\n",
    "        print(f\"  Val   Loss: {val_loss:.4f} | MAE: {val_m['mae']:.2f}m | RMSE: {val_m['rmse']:.2f}m | R2: {val_m['r2']:.4f}\")\n",
    "        \n",
    "        # Save Best Model theo MAE\n",
    "        if val_m['mae'] < best_mae:\n",
    "            best_mae = val_m['mae']\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), cfg.MODEL_SAVE_PATH)\n",
    "            print(f\"  âœ… Model Saved (New Best MAE: {best_mae:.4f}m)\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            print(f\"  âš ï¸ No improve ({patience}/{cfg.EARLY_STOP_PATIENCE})\")\n",
    "            \n",
    "        if patience >= cfg.EARLY_STOP_PATIENCE:\n",
    "            print(\"ðŸ›‘ Early Stopping!\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd138cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET INITIALIZATION\n",
      "============================================================\n",
      "Image Size: 13879 x 16445\n",
      "Loading label band to generate patches...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Valid Patches found: 2120\n",
      "âœ… Total GEDI Pixels: 481299\n",
      "============================================================\n",
      "\n",
      "Train size: 1696 patches\n",
      "Val size: Â  424 patches\n",
      "\n",
      "ðŸ”Ž STARTING LR FINDER (Manual Analysis Mode)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db70df6de1e2410f83f16d736ce6f604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 11.71 GiB of which 65.31 MiB is free. Process 1375449 has 244.00 MiB memory in use. Process 1417386 has 11.40 GiB memory in use. Of the allocated memory 11.17 GiB is allocated by PyTorch, and 63.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 426\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 426\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 385\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# 3. Model & Optimizer Setup\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# --- LR Finder Logic ---\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mUSE_LR_FINDER:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Cháº¡y LR Finder Ä‘á»ƒ cáº­p nháº­t LR tá»‘i Æ°u\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     found_lr \u001b[38;5;241m=\u001b[39m \u001b[43mfind_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUNetPlusPlus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mLR \u001b[38;5;241m=\u001b[39m found_lr \n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Khá»Ÿi táº¡o model vÃ  optimizer CHÃNH THá»¨C\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 326\u001b[0m, in \u001b[0;36mfind_lr\u001b[0;34m(model_class, train_loader, optimizer_class, device, cfg)\u001b[0m\n\u001b[1;32m    322\u001b[0m lr_finder_optimizer \u001b[38;5;241m=\u001b[39m optimizer_class(lr_finder_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m    324\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m LRFinder(lr_finder_model, lr_finder_optimizer, lr_finder_loss_wrapper, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 326\u001b[0m \u001b[43mlr_finder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Láº¥y dá»¯ liá»‡u Loss vÃ  LR Ä‘Ã£ thu tháº­p\u001b[39;00m\n\u001b[1;32m    329\u001b[0m lrs \u001b[38;5;241m=\u001b[39m lr_finder\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_lr_finder/lr_finder.py:345\u001b[0m, in \u001b[0;36mLRFinder.range_test\u001b[0;34m(self, train_loader, val_loader, start_lr, end_lr, num_iter, step_mode, smooth_f, diverge_th, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`val_loader` has unsupported type: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected types are `torch.utils.data.DataLoader`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor child of `ValDataLoaderIter`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(val_loader))\n\u001b[1;32m    341\u001b[0m         )\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_iter)):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# Train on batch and retrieve loss\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking_transfer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking_transfer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loader:\n\u001b[1;32m    351\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(\n\u001b[1;32m    352\u001b[0m             val_iter, non_blocking_transfer\u001b[38;5;241m=\u001b[39mnon_blocking_transfer\n\u001b[1;32m    353\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_lr_finder/lr_finder.py:410\u001b[0m, in \u001b[0;36mLRFinder._train_batch\u001b[0;34m(self, train_iter, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    408\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# Loss should be averaged in each step\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 215\u001b[0m, in \u001b[0;36mUNetPlusPlus.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m x2_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2_2(torch\u001b[38;5;241m.\u001b[39mcat([x2_0, x2_1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x3_1)], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    214\u001b[0m x1_3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1_3(torch\u001b[38;5;241m.\u001b[39mcat([x1_0, x1_1, x1_2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(x2_2)], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 215\u001b[0m x0_4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv0_4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx0_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1_3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(x0_4)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 163\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2813\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2811\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 11.71 GiB of which 65.31 MiB is free. Process 1375449 has 244.00 MiB memory in use. Process 1417386 has 11.40 GiB memory in use. Of the allocated memory 11.17 GiB is allocated by PyTorch, and 63.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "from torch_lr_finder import LRFinder \n",
    "\n",
    "# ================================================================================\n",
    "# CANOPY HEIGHT MAPPING - UNET++ TRAINING (FINAL OPTIMIZED)\n",
    "# Paper Ref: Deng et al., 2025 - Forests 16(11):1663\n",
    "# ================================================================================\n",
    "\n",
    "# ================= 1. CONFIGURATION =================\n",
    "class Config:\n",
    "    # --- File Paths ---\n",
    "    TIFF_PATH = \"./DakLak_Full_Merged.tif\"\n",
    "    MODEL_SAVE_PATH = \"best_unetpp_canopy_height.pth\"\n",
    "    \n",
    "    # --- Training Hyperparameters ---\n",
    "    PATCH_SIZE = 256\n",
    "    BATCH_SIZE = 24  # ÄÃ£ tÄƒng Ä‘á»ƒ phÃ¹ há»£p vá»›i 2x RTX 3090 (cÃ³ thá»ƒ tÄƒng lÃªn 32 náº¿u cáº§n)\n",
    "    LR = 1e-4  # LR ban Ä‘áº§u (sáº½ Ä‘Æ°á»£c cáº­p nháº­t náº¿u USE_LR_FINDER=True)\n",
    "    EPOCHS = 200\n",
    "    EARLY_STOP_PATIENCE = 15\n",
    "    \n",
    "    # --- Data Params ---\n",
    "    MAX_CANOPY_HEIGHT = 100.0  \n",
    "    \n",
    "    # --- Optimizer & Scheduler ---\n",
    "    USE_LR_FINDER = True \n",
    "    SCHEDULER_TYPE = 'onecycle' \n",
    "    \n",
    "    # --- Band Configuration ---\n",
    "    # Band 1: GEDI Label (RH98) - Target\n",
    "    # Band 2-15: Sentinel-1 & Sentinel-2 Inputs (14 kÃªnh)\n",
    "    LABEL_BAND_IDX = 1\n",
    "    INPUT_BAND_INDICES = list(range(2, 14))\n",
    "    INPUT_CHANNELS = 12\n",
    "    \n",
    "    # --- System ---\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    NUM_WORKERS = 4 \n",
    "    PIN_MEMORY = True\n",
    "    \n",
    "    # --- Split Ratio & Seed ---\n",
    "    TRAIN_RATIO = 0.8\n",
    "    VAL_RATIO = 0.2\n",
    "    SEED = 42\n",
    "\n",
    "# ================= 2. DATASET =================\n",
    "class CanopyHeightDataset(Dataset):\n",
    "    def __init__(self, tif_path, config, augment=True):\n",
    "        self.tif_path = tif_path\n",
    "        self.cfg = config\n",
    "        self.augment = augment\n",
    "        self.windows = []\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"DATASET INITIALIZATION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        if not os.path.exists(tif_path):\n",
    "            raise FileNotFoundError(f\"âŒ KhÃ´ng tÃ¬m tháº¥y file: {tif_path}\")\n",
    "\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            self.H, self.W = src.height, src.width\n",
    "            print(f\"Image Size: {self.H} x {self.W}\")\n",
    "            print(\"Loading label band to generate patches...\")\n",
    "            \n",
    "            try:\n",
    "                label_data = src.read(config.LABEL_BAND_IDX)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error reading label: {e}\")\n",
    "                return\n",
    "        \n",
    "        patch_size = config.PATCH_SIZE\n",
    "        stride = patch_size\n",
    "        \n",
    "        n_rows = (self.H - patch_size) // stride + 1\n",
    "        n_cols = (self.W - patch_size) // stride + 1\n",
    "        \n",
    "        gedi_pixels_total = 0\n",
    "        \n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_cols):\n",
    "                row_off = i * stride\n",
    "                col_off = j * stride\n",
    "                \n",
    "                window = rasterio.windows.Window(col_off, row_off, patch_size, patch_size)\n",
    "                patch_label = label_data[row_off:row_off+patch_size, col_off:col_off+patch_size]\n",
    "                \n",
    "                # Lá»ŒC: Chá»‰ láº¥y patch cÃ³ Ã­t nháº¥t 1 Ä‘iá»ƒm GEDI há»£p lá»‡ (>0.5m)\n",
    "                valid_gedi = ((patch_label > 0.5) & (patch_label < 100)).sum()\n",
    "                \n",
    "                if valid_gedi > 0:\n",
    "                    self.windows.append(window)\n",
    "                    gedi_pixels_total += valid_gedi\n",
    "                    \n",
    "        print(f\"âœ… Valid Patches found: {len(self.windows)}\")\n",
    "        print(f\"âœ… Total GEDI Pixels: {gedi_pixels_total}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window = self.windows[idx]\n",
    "        \n",
    "        with rasterio.open(self.tif_path) as src:\n",
    "            img = src.read(self.cfg.INPUT_BAND_INDICES, window=window).astype('float32')\n",
    "            label = src.read(self.cfg.LABEL_BAND_IDX, window=window).astype('float32')\n",
    "        \n",
    "        img = np.nan_to_num(img, nan=0.0)\n",
    "        img = np.clip(img, 0, 1.0)\n",
    "        \n",
    "        label = np.nan_to_num(label, nan=0.0)\n",
    "        mask = ((label > 0.5) & (label < 100.0)).astype('float32')\n",
    "        \n",
    "        label = np.clip(label, 0, self.cfg.MAX_CANOPY_HEIGHT) / self.cfg.MAX_CANOPY_HEIGHT\n",
    "        label = label * mask \n",
    "        \n",
    "        img_t = torch.from_numpy(img)\n",
    "        label_t = torch.from_numpy(label).unsqueeze(0)\n",
    "        mask_t = torch.from_numpy(mask).unsqueeze(0)\n",
    "        \n",
    "        # Augmentation\n",
    "        if self.augment:\n",
    "            if random.random() > 0.5:\n",
    "                img_t = TF.hflip(img_t)\n",
    "                label_t = TF.hflip(label_t)\n",
    "                mask_t = TF.hflip(mask_t)\n",
    "            if random.random() > 0.5:\n",
    "                img_t = TF.vflip(img_t)\n",
    "                label_t = TF.vflip(label_t)\n",
    "                mask_t = TF.vflip(mask_t)\n",
    "            if random.random() > 0.5:\n",
    "                angle = random.choice([90, 180, 270])\n",
    "                img_t = TF.rotate(img_t, angle)\n",
    "                label_t = TF.rotate(label_t, angle)\n",
    "                mask_t = TF.rotate(mask_t, angle)\n",
    "                \n",
    "        return img_t, label_t, mask_t\n",
    "\n",
    "# ================= 3. MODEL (UNet++) =================\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.conv(x)\n",
    "\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    def __init__(self, in_channels=12, out_channels=1):\n",
    "        super(UNetPlusPlus, self).__init__()\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv0_0 = ConvBlock(in_channels, nb_filter[0])\n",
    "        self.conv1_0 = ConvBlock(nb_filter[0], nb_filter[1])\n",
    "        self.conv2_0 = ConvBlock(nb_filter[1], nb_filter[2])\n",
    "        self.conv3_0 = ConvBlock(nb_filter[2], nb_filter[3])\n",
    "        self.conv4_0 = ConvBlock(nb_filter[3], nb_filter[4])\n",
    "        \n",
    "        self.conv0_1 = ConvBlock(nb_filter[0]+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_1 = ConvBlock(nb_filter[1]+nb_filter[2], nb_filter[1])\n",
    "        self.conv2_1 = ConvBlock(nb_filter[2]+nb_filter[3], nb_filter[2])\n",
    "        self.conv3_1 = ConvBlock(nb_filter[3]+nb_filter[4], nb_filter[3])\n",
    "        \n",
    "        self.conv0_2 = ConvBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_2 = ConvBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1])\n",
    "        self.conv2_2 = ConvBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2])\n",
    "        \n",
    "        self.conv0_3 = ConvBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_3 = ConvBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1])\n",
    "        \n",
    "        self.conv0_4 = ConvBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0])\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(nb_filter[0], out_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "        \n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "        \n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "        \n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "        \n",
    "        output = self.final(x0_4)\n",
    "        return output\n",
    "\n",
    "# ================= 4. LOSS & METRICS =================\n",
    "def masked_mae_loss(preds, targets, mask):\n",
    "    diff = torch.abs(preds - targets) * mask\n",
    "    loss = diff.sum() / (mask.sum() + 1e-6)\n",
    "    return loss\n",
    "\n",
    "# HÃ m Loss Wrapper cho LRFinder (KHÃ”NG DÃ™NG MASK)\n",
    "def lr_finder_loss_wrapper(preds, targets):\n",
    "    return torch.abs(preds - targets).mean()\n",
    "\n",
    "def calculate_metrics(preds, targets, mask, max_height=100.0):\n",
    "    preds_m = preds * max_height\n",
    "    targets_m = targets * max_height\n",
    "    \n",
    "    p = preds_m.detach().cpu().numpy().flatten()\n",
    "    t = targets_m.detach().cpu().numpy().flatten()\n",
    "    m = mask.detach().cpu().numpy().flatten()\n",
    "    \n",
    "    valid_indices = m > 0\n",
    "    if valid_indices.sum() < 2:\n",
    "        return {'r2': 0.0, 'rmse': 0.0, 'mae': 0.0}\n",
    "        \n",
    "    p_valid = p[valid_indices]\n",
    "    t_valid = t[valid_indices]\n",
    "    \n",
    "    valid_mask = np.isfinite(p_valid) & np.isfinite(t_valid)\n",
    "    p_valid = p_valid[valid_mask]\n",
    "    t_valid = t_valid[valid_mask]\n",
    "    \n",
    "    if len(p_valid) < 2:\n",
    "        return {'r2': 0.0, 'rmse': 0.0, 'mae': 0.0}\n",
    "        \n",
    "    r2 = r2_score(t_valid, p_valid)\n",
    "    rmse = np.sqrt(mean_squared_error(t_valid, p_valid))\n",
    "    mae = mean_absolute_error(t_valid, p_valid)\n",
    "    \n",
    "    return {'r2': r2, 'rmse': rmse, 'mae': mae}\n",
    "\n",
    "# ================= 5. TRAINING ROUTINE =================\n",
    "def train_one_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    metrics_accum = {'r2': 0, 'rmse': 0, 'mae': 0}\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Train\")\n",
    "    for img, label, mask in pbar:\n",
    "        img, label, mask = img.to(device), label.to(device), mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(img)\n",
    "        \n",
    "        loss = masked_mae_loss(preds, label, mask)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_metrics = calculate_metrics(preds, label, mask, Config.MAX_CANOPY_HEIGHT)\n",
    "            for k in metrics_accum:\n",
    "                metrics_accum[k] += batch_metrics[k]\n",
    "                \n",
    "        pbar.set_postfix({'Loss': f\"{loss.item():.4f}\", 'MAE': f\"{batch_metrics['mae']:.2f}m\"})\n",
    "        \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    avg_metrics = {k: v / len(dataloader) for k, v in metrics_accum.items()}\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "def validate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    metrics_accum = {'r2': 0, 'rmse': 0, 'mae': 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, label, mask in tqdm(dataloader, desc=\"Val\"):\n",
    "            img, label, mask = img.to(device), label.to(device), mask.to(device)\n",
    "            \n",
    "            preds = model(img)\n",
    "            loss = masked_mae_loss(preds, label, mask)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            batch_metrics = calculate_metrics(preds, label, mask, Config.MAX_CANOPY_HEIGHT)\n",
    "            for k in metrics_accum:\n",
    "                metrics_accum[k] += batch_metrics[k]\n",
    "                \n",
    "    avg_loss = val_loss / len(dataloader)\n",
    "    avg_metrics = {k: v / len(dataloader) for k, v in metrics_accum.items()}\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "# ================= 6. LR FINDER LOGIC =================\n",
    "def find_lr(model_class, train_loader, optimizer_class, device, cfg):\n",
    "    \"\"\"Thá»±c hiá»‡n tÃ¬m kiáº¿m Learning Rate tá»‘i Æ°u thá»§ cÃ´ng.\"\"\"\n",
    "    print(\"\\nðŸ”Ž STARTING LR FINDER (Manual Analysis Mode)...\")\n",
    "    \n",
    "    # Khá»Ÿi táº¡o láº¡i model vÃ  optimizer cho LR Finder\n",
    "    lr_finder_model = model_class(in_channels=cfg.INPUT_CHANNELS, out_channels=1).to(device)\n",
    "    lr_finder_optimizer = optimizer_class(lr_finder_model.parameters(), lr=1e-7, weight_decay=1e-4)\n",
    "    \n",
    "    lr_finder = LRFinder(lr_finder_model, lr_finder_optimizer, lr_finder_loss_wrapper, device=device)\n",
    "    \n",
    "    lr_finder.range_test(train_loader, end_lr=1, num_iter=100, step_mode=\"exp\")\n",
    "    \n",
    "    # Láº¥y dá»¯ liá»‡u Loss vÃ  LR Ä‘Ã£ thu tháº­p\n",
    "    lrs = lr_finder.history['lr']\n",
    "    losses = lr_finder.history['loss']\n",
    "    \n",
    "    # ----------------------------------------------------\n",
    "    # TÃŒM KIáº¾M LR Tá»I Æ¯U THá»¦ CÃ”NG (Tim Ä‘iá»ƒm dá»‘c nháº¥t)\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    gradients = np.gradient(np.array(losses))\n",
    "    skip_steps = int(len(losses) * 0.15) \n",
    "    min_gradient_index = np.argmin(gradients[skip_steps:]) + skip_steps\n",
    "    \n",
    "    suggested_lr = lrs[min_gradient_index]\n",
    "    best_lr = suggested_lr / 10 \n",
    "    \n",
    "    print(f\"\\nâœ… LR FINDER COMPLETED.\")\n",
    "    print(f\"ðŸ‘‰ Suggested Optimal LR (Äiá»ƒm dá»‘c nháº¥t): {suggested_lr:.2e}\")\n",
    "    print(f\"ðŸ‘‰ Using Base LR (Suggested/10) for training: {best_lr:.2e}\")\n",
    "    \n",
    "    lr_finder.reset()\n",
    "    \n",
    "    return best_lr\n",
    "\n",
    "# ================= 7. MAIN =================\n",
    "def main():\n",
    "    cfg = Config()\n",
    "    \n",
    "    # 1. Reproducibility\n",
    "    random.seed(cfg.SEED)\n",
    "    np.random.seed(cfg.SEED)\n",
    "    torch.manual_seed(cfg.SEED)\n",
    "    \n",
    "    # 2. Dataset Setup\n",
    "    if not os.path.exists(cfg.TIFF_PATH):\n",
    "        print(f\"âŒ Error: Not found {cfg.TIFF_PATH}\")\n",
    "        return\n",
    "\n",
    "    full_dataset = CanopyHeightDataset(cfg.TIFF_PATH, cfg)\n",
    "    \n",
    "    train_size = int(cfg.TRAIN_RATIO * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_ds, val_ds = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(cfg.SEED)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    print(f\"Train size: {len(train_ds)} patches\")\n",
    "    print(f\"Val size: Â  {len(val_ds)} patches\")\n",
    "    \n",
    "    # 3. Model & Optimizer Setup\n",
    "    \n",
    "    # --- LR Finder Logic ---\n",
    "    if cfg.USE_LR_FINDER:\n",
    "        # Cháº¡y LR Finder Ä‘á»ƒ cáº­p nháº­t LR tá»‘i Æ°u\n",
    "        found_lr = find_lr(UNetPlusPlus, train_loader, optim.AdamW, cfg.DEVICE, cfg)\n",
    "        cfg.LR = found_lr \n",
    "        \n",
    "    # Khá»Ÿi táº¡o model vÃ  optimizer CHÃNH THá»¨C\n",
    "    model = UNetPlusPlus(in_channels=cfg.INPUT_CHANNELS, out_channels=1).to(cfg.DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=cfg.LR/10, weight_decay=1e-4) \n",
    "    \n",
    "    # OneCycleLR Scheduler\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=cfg.LR, \n",
    "        steps_per_epoch=len(train_loader), epochs=cfg.EPOCHS\n",
    "    )\n",
    "    \n",
    "    # 4. Loop\n",
    "    best_mae = float('inf')\n",
    "    patience = 0\n",
    "    \n",
    "    print(\"\\nðŸš€ START TRAINING...\")\n",
    "    for epoch in range(1, cfg.EPOCHS+1):\n",
    "        train_loss, train_m = train_one_epoch(model, train_loader, optimizer, scheduler, cfg.DEVICE)\n",
    "        val_loss, val_m = validate(model, val_loader, cfg.DEVICE)\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{cfg.EPOCHS}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | MAE: {train_m['mae']:.2f}m | RMSE: {train_m['rmse']:.2f}m | R2: {train_m['r2']:.4f}\")\n",
    "        print(f\"  Val   Loss: {val_loss:.4f} | MAE: {val_m['mae']:.2f}m | RMSE: {val_m['rmse']:.2f}m | R2: {val_m['r2']:.4f}\")\n",
    "        \n",
    "        # Save Best Model theo MAE\n",
    "        if val_m['mae'] < best_mae:\n",
    "            best_mae = val_m['mae']\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), cfg.MODEL_SAVE_PATH)\n",
    "            print(f\"  âœ… Model Saved (New Best MAE: {best_mae:.4f}m)\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            print(f\"  âš ï¸ No improve ({patience}/{cfg.EARLY_STOP_PATIENCE})\")\n",
    "            \n",
    "        if patience >= cfg.EARLY_STOP_PATIENCE:\n",
    "            print(\"ðŸ›‘ Early Stopping!\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "913259d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1218.04s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_lr_finder\n",
      "  Downloading torch_lr_finder-0.2.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (3.10.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (2.2.6)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (2.9.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torch_lr_finder) (25.0)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.3.20)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.20.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (12.8.93)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (2.27.5)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (12.8.93)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (12.8.90)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (3.1.6)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch_lr_finder) (0.7.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (1.4.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (1.3.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch_lr_finder) (11.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->torch_lr_finder) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=0.4.1->torch_lr_finder) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->torch_lr_finder) (3.0.2)\n",
      "Installing collected packages: torch_lr_finder\n",
      "Successfully installed torch_lr_finder-0.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch_lr_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178fb46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "534.01s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.2.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.2.6)\n",
      "Collecting click-plugins\n",
      "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (25.3.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.5)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2025.8.3)\n",
      "Collecting affine\n",
      "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4353eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "559.14s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.7.1\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.9.90\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.8.90\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 KB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvshmem-cu12==3.3.20\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.10.2.21\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.8.93\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.20.0)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.8.93\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.8.90\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufile-cu12==1.13.1.3\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting networkx>=2.5.1\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=0.8.5\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.0/201.0 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.8.4.1\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.15.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.3.90\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.6)\n",
      "Collecting triton==3.5.1\n",
      "  Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.8.90\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.27.5\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.28.9\n",
      "    Uninstalling nvidia-nccl-cu12-2.28.9:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.28.9\n",
      "Successfully installed fsspec-2025.10.0 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.1 triton-3.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
